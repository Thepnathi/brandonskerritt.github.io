---
title: "Matrices"
categories:
  - University
---

A matrix is a container which can have many dimensions. Paul said that this won't be on the *first class test* but he might ask you to multiply matrices out.

We can represent a shape by representing its "corners" in a vector like so:

$$ <(x_1, y_1), (x_2, y_2), (x_3, y_3), (x_4, y_4)>$$

So most shapes are just corners with them filed in.

Take this square for instance:

![img](https://screenshotscdn.firefoxusercontent.com/images/0a1b5673-94e3-43d4-b18f-62147d016753.png)

If you know the corners of this square, you just draw the corners, connect them to one another and colour it in. Almost all shapes have this property (not circles, since circles do not have corners).

If we wanted to scale this shape by a factor of s, we can use this matrix:

$$\begin{pmatrix}s & 0\\\ 0 & s\end{pmatrix} \begin{pmatrix}y_i \\\ x_i\end{pmatrix}$$

To "scale a shape" means to increase / decrease the size of the shape. If we increase how far away the corners are away from eachother then we increse the size of the shape.

So you have a vector, which can be represented as a matrix. Just to drive the point home:

$$<x_1, y_1> = \begin{pmatrix}x_1 \\\ y_1 \end{pmatrix}$$

This is just one corner, we obviously scale every corner by the scalar but we start with one corner and work our way through all the corners.

$$\begin{pmatrix}s & 0 & 0\\\ 0 & s & 0 \\\ 0 & 0 & s \end{pmatrix} \begin{pmatrix}y_i \\\ x_i \\\ z_i \end{pmatrix}$$

This is how you scale a 3-dimensional object.

The matrix applied to scale the vector is an example of a *linear transformation*.

An operation, T, is a _*linear transformation*_ if:
1. For any pair of vectors, v and u, belonging to the vector space, V:
  T(v + u) = T(v) + T(u)
2. For every vector in V and any r (real number) in the set used by R (natural numbers, real, rational):
  T(rv) = rT(v)

What if we wanted to move a point, say <1, 2> to <5, 6>?

Well, this is easy!

$$\begin{pmatrix}1 & 0 & 4 \\\ 0 & 1 & 4 \\\ 0 & 0 & 1 \end{pmatrix} \begin{pmatrix}4 \\\ 4 \\\ 1 \end{pmatrix} = \begin{pmatrix}5 \\\ 6 \\\ 1 \end{pmatrix} $$

The difference between 1 and 5 is 4, so that's why the 4 is there. 

We can generalise this like so:

Say you want to move a point <x, y> to the point <x + p, y + q>

$$\begin{pmatrix}1 & 0 & p \\\ 0 & 1 & q \\\ 0 & 0 & 1 \end{pmatrix} \begin{pmatrix}x \\\ y \\\ 1 \end{pmatrix} = \begin{pmatrix}5 \\\ 6 \\\ 1 \end{pmatrix}$$

What if we wanted to rotate a a point anticlockwise about <0, 0> by theta to <q, s>?

![img](https://screenshotscdn.firefoxusercontent.com/images/bd251a58-13a7-4055-beaa-013e0e474ba9.png)

# Advance Matrices

An n x n matrix has n rows and n columns. The value in row i and column j of the matrix is denoted as:

$$ a_{ij}$$

The number of rows and columns do not have to be equal, but in most cases they are.

## Directed Graphs represent in Matrices

We can represent directed graphs using matrices.

The following graph can be represented by the 5 x 5 matrix:

![img](https://screenshotscdn.firefoxusercontent.com/images/ce6d115e-d8cd-4a03-b1ba-42fae68f56e2.png)

$$\begin{pmatrix}0 & 1 & 1 & 0 & 0 \\\ 0 & 0 & 1 & 0 & 0 \\\ 1 & 0 & 0 & 1 & 1 \\\ 1 & 0 & 0 & 0 & 0 \\\ 0 & 0 & 0 & 1 & 0\end{pmatrix}$$

Where the rows are nodes 1 to 5 and so are the columns. If node 1 is connected to node 2, row 1 column 2 is set to 1. If node 2 is not connect to node 1, row 2 column 1 is set to 0.

## Adding Matrices

We have 2 matrices, A and B. We want to add them like so:

$$ C = A + B$$

We can add them like so:

$$ c_{ij} = a_{ij} + b_{ij} \space for \space each \space 1 \le i \le n, 1 \le j \le m$$

So we just add the corresponding element in each matrix.

We can't mix dimensions with addition of matrices.

We can scale a matrix by a real number, R, like so:

$$ C = rA \ space in \space which \space [c_{ij}] = [r * {a_ij}] = [ra_{ij}]$$

## Multiplying Matrices

The matrix A with n rows and m colums and our second matrix B with m rows and r columns.

When we multiply them together the resulting matrix, C, will have n rows and r columns. The number of rows in the first matrix has to be the same as the number of columns in our second matrix.

$$ c_{ij} =\sum_{k=1}^m a_{ik} * b_{kj} = \sum_{k=1}^m a_{ik}b_{kj}$$

So we just multiply all of the entries in the ith row by all of the entries in the jth column in the two matrices.

## Symetric Matrices

With two matrices they are said to be symetric when:

$$a_{ij} = a_{ji}$$

When the item in the ith row and jth column is equal to the item in the jth row and ith column for every item in the matrices they are said to be equal.

## Identity Matrix

The n x n Identity matrix uses only the values 0 and 1.

If the values in the ith row and jth column are equal, that data point is a 1. If they are not equal, the data point is a 0.

Take any n x n matrix, A.

Then the identity matrix, I, satisfies:

$$ AI = IA = A$$

Multiplying any matrix by the identity matrix results in the original matrix.

## Inverse of a Matrix

We want to find a matrix which is the inverse of A given by the symbol:

$$ A^{-1}$$

Which has the property

$$ A * A^{-1} = A^{-1} * A = I $$

Where if you multiply the inverse of a matrix by the matrix you will find the identity matrix.

Not all matrices have an inverse. The singular number 0 has no inverse.

When a matrix **does not** have an inverse it is referred to singular.

The inverse of a matrix is useful 

TK identity matrix?
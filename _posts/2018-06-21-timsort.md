---
title: "Timsort"
categories:
  - blog
---

Timsort is a sorting algorithm that is efficient for real-world data and not created in a academic laboratory. Timsort was created by Tim Peters for the Python programming language in 2001. Timsort first analyses the list it is trying to sort and then chooses an approach based on the list.

Since the algorithm has been invented it has been used as the default sorting algorithm in Python, Java, the Android Platform, and in versions of GNU.

Timsort was designed to use already-ordered elements that already exist in most real-world data. It calls these already-ordered elements "natural runs". It iterates over the data collecting the elements into runs, and simultaneously merging those runs together into one.

# The array has fewer than 64 elements in it

If the array has fewer than 64 elements in it, timsort will execute an insertion sort.

An insertion sort is a simple sort which is most effective on small lists. It is quite slow at larger lists, but very fast with small lists. The idea of an insertion sort is as follows:

** Look at elements one by one
** Build up sorted list by inserting the element at the correct location

Here's a trace table showing how insertion sort would sort the list [34, 10, 64, 51, 32, 21]

|       [34, 10, 64, 51, 32, 21]       | No. shifted to right |
| ------------------------------------ | -------------------- |
| [34, 10, 64, 51, 32, 21]             | Nothing yet |
| [10, **34**, 64, 51, 32, 21]             | 34 |
| [**10**, **34**, 64, 51, 32, 21]         | Nothing yet |
| [**10**, **34**, **51**, 64, 32, 21]       | 64 |
| [**10**, **32**, **34**, **51**, **64**, 21]   | 34, 51, 64 |
| [**10**, **21**, **32**, **34**, **51**, **64**] | 32, 34, 51, 64 |

In this instance we are inserting the newly sorted elements into a new sub-array, which starts at the start of the array.

Here's a gif showing insertion sort:

![img](https://upload.wikimedia.org/wikipedia/commons/9/9c/Insertion-sort-example.gif)

# More about runs

If the list is larger than 64 elements than the algorithm will make a first pass through the list looking for parts that are strictly increasing or decreasing. If the part is decreasing, it will reverse that part.

The minrun is a size which is determined based on the size of the array. It is selected so that most runs in a random array are, or become minrun, in length. Merging 2 arrays is more efficient when the number of runs is equal to, or slightly less than, a power of two. Timsort chooses minrun to try to ensure this efficiency.

Minrun is chosen from the range 32 to 64 inclusive, such that the length of the original array, when divided by minrun, is equal to or slightly less than a power of two. 

If the run is less than minrun, you calculate the length of that run away from minrun. Using this new number, you grab that many items ahead of the run and perform an insertion sort to create a new run.

After this part has completed we should now have a bunch of sorted runs in a list.

# Merging

Timsort now performs mergesort to merge the runs together, however, Timsort makes sure to maintain stabillity and merge balance whilest merge sorting.

In order to maintain stabillity we should not exchange 2 numbers of equal value. This not only keeps their original positions in the list but enables the algorithm to become faster.

As Timsort finds runs, it adds them to a stack. A simple stack would look like this:

| a |
| --- | 
| b |
| c |

Imagine a stack of plates. You cannot take plates from the bottom, so you have to take them from the top. The same is true about a stack.

Timsort tries to balance two competing needs when mergesort runs. On one hand, we would like to delay merging as long as possible in order to exploit patterns that may come up later. But we would like even more to do the merging as soon as possible to exploit the run that the run just found is still high in the memory hierachy. We also can't delay merging "too long" because it consumes memory to remember the runs that are stil unmerged, and the stack has a fixed size.

To make sure we have this compromise, Timsort keeps track of the three most recent items on the stack and creates two laws that must hold true of those items:

1. A > B + C
2. B > C

In the words of Tim Peters himself:

> What turned out to be a good compromise maintains two invariants on the stack entries, where A, B and C are the lengths of the three righmost not-yet merged slices


Usually, merging adjacent runs of different lengths in place (remember that stable thing) is very hard. In order to get around this, Timsort sets aside some temporary memory, and places the smaller of the two runs (let’s call them a and b) into that temporary space. 

Or, imagine the line of ladies in white from the video move their line over to stage left in front of the men. They perform the same operation (or dance) checking the first item in a (women) against b(men), and the victor fills in the spaces that a has vacated. (If b is smaller the merge sort has to be performed backwards, but I won’t go into that.)

Actually, what Timsort does is slightly more complicated than this, which brings me to the last point:

# Galloping

So, Timsort is going along merging a and b, and it notices that one run or the other has been “winning” many times in a row. For a concrete example, imagine if, in the dancing video, it turned out that all the women had lower numbers than all the men. All the women would just end up standing back in their original places, but after doing a lot of extra work.

Timsort takes advantage of the fact that data often has some preexisting internal structure, and assumes that if a lot of a’s values are lower than b’s, then it is likely that a will continue to have smaller values than b.

Timsort then enters “galloping mode.” Instead of checking the first/leftmost unsorted values of a and b against one another (i.e. going through one at a time), Timsort performs a binary search for the appropriate position of b[0] in a[0]. That way, a whole slice of a can be moved back into place. Then it searches for the appropriate location of a[0] in b, and a whole section of b can be moved at once.

It turns out, this operation is not worth it if the appropriate location for b[0] is very close to the beginning of a (or vice versa), so gallop mode quickly exits if it isn’t paying off. Additionally, Timsort takes note, and makes it harder to enter gallop mode later by increasing the number of consecutive a-only or b-only wins required to enter. If gallop mode is paying off, Timsort makes it easier to reenter.


And there you have it, Timsort.

An interesting note: Though Timsort’s great performance on arrays with some preexisting internal sorting is its best-known feature, it seems like having a stable sort was one of the main motivators behind adopting timsort. Previously, in order to achieve a stable sort, you’d have to zip the items in your list up with integers, and sort it as an array of tuples. How irritating.

P.S. I know I’ve glossed over some complexity here, but that aside, if you’re reading this and think I’ve totally misunderstood or mis-explained something, just head on over to my github, and shoot me an email to let me know.


https://bugs.python.org/file4451/timsort.txt
